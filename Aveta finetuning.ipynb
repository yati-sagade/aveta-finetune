{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found a pre-trained model for a lane boundary following self-driving bot [here](https://rope.donkeycar.com/nets/1/). The model is also stored in ./all_lined_tracks_linear.h5. The idea is to finetune it with a few dense layers and our own dataset in github.com/yati-sagade/aveta-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, Input\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_in (InputLayer)             (None, 120, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 58, 78, 24)   1824        img_in[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 27, 37, 32)   19232       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 12, 17, 64)   51264       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 5, 8, 64)     36928       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 3, 6, 64)     36928       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flattened (Flatten)             (None, 1152)         0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          115300      flattened[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           5050        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "angle_out (Dense)               (None, 15)           765         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "throttle_out (Dense)            (None, 1)            51          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 267,342\n",
      "Trainable params: 267,342\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/models.py:318: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = load_model('all_lined_tracks_linear.h5')\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to pop out the angle_out and throttle_out tensors and stack two dense layers, of sizes 32, 16, followed by the output layer with two units. The two hidden units can have the sigmoid activation while it is convenient for the output layer units to have tanh activation because of the nice `[-1, 1]` range, which I can map to wheel speeds in either direction quite easily. Note that an output of 1 shall correspond to a speed of 255 and -1 to a speed of -255, which is what the motot HAT library we are using for Aveta expects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network():\n",
    "    img_in = Input(shape=(120, 160, 3), name='img_in')\n",
    "\n",
    "    x = Conv2D(24, (5, 5), name='conv2d_1', activation='relu', strides=(2, 2))(img_in)\n",
    "    x = Conv2D(32, (5, 5), name='conv2d_2', activation='relu', strides=(2, 2))(x)\n",
    "    x = Conv2D(64, (5, 5), name='conv2d_3', activation='relu', strides=(2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), name='conv2d_4', activation='relu', strides=(2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), name='conv2d_5', activation='relu', strides=(1, 1))(x)\n",
    "    x = Flatten(name='flattened')(x)\n",
    "    x = Dense(100, activation='relu', name='dense_1')(x)\n",
    "    x = Dropout(rate=0.1, name='dropout_1')(x)\n",
    "    x = Dense(50, activation='relu', name='dense_2')(x)\n",
    "    x = Dropout(rate=0.1, name='dropout_2')(x)\n",
    "    # This is the beginning of our additions\n",
    "    x = Dense(32, activation='sigmoid', name='dense_3')(x)\n",
    "    x = Dropout(rate=0.1, name='dropout_3')(x)\n",
    "    x = Dense(16, activation='sigmoid', name='dense_4')(x)\n",
    "    x = Dropout(rate=0.1, name='dropout_4')(x)\n",
    "\n",
    "    speeds_out = Dense(2, activation='tanh', name='dense_5')(x)\n",
    "\n",
    "    model = Model(inputs=[img_in], outputs=[speeds_out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img_in (InputLayer)          (None, 120, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 58, 78, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 37, 32)        19232     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 17, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flattened (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 268,720\n",
      "Trainable params: 268,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_network()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not know of a way to generate python code from a stored Keras model, so I had to dig into the JSON representation of the model and write out the model by hand. Of course I've left out the last two layers of the original model, and instead (after the dropout_2 layer) added my own dense layers. I don't have a huge dataset, so I've included dropout layers to guard against overfitting. This may not be needed.\n",
    "\n",
    "Now to transfer the weights of the pretrained model onto our model's first layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img_in (InputLayer)          (None, 120, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 58, 78, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 37, 32)        19232     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 17, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flattened (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 268,720\n",
      "Trainable params: 2,194\n",
      "Non-trainable params: 266,526\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if layer.name == 'dense_3':\n",
    "        break # Starting here, it's our layers\n",
    "    weights = pretrained_model.get_layer(name=layer.name).get_weights()\n",
    "    layer.set_weights(weights)\n",
    "    layer.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to massage the training data so that we have the following:\n",
    "- A suitable train/test split\n",
    "- Speeds are in speeds.txt, and need to be normalized in the `[-1, 1]` by simply dividing by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:24: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:28: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:28: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: train_x: (7065, 120, 160, 3), train_y: (7065, 2), test_x: (785, 120, 160, 3), test_y: (785, 2)\n",
      "-0.09411764705882353 0.6588235294117647\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "TEST_MODE = False\n",
    "AVETA_DATA_DIR = os.path.expanduser('~/aveta-data')\n",
    "\n",
    "imdir = os.path.join(AVETA_DATA_DIR, 'generated')\n",
    "imfiles = [f for f in os.listdir(imdir) if f.endswith('.jpg')]\n",
    "random.shuffle(imfiles)\n",
    "\n",
    "if TEST_MODE:\n",
    "    imfiles = imfiles[:100]\n",
    "\n",
    "speedfile = os.path.join(imdir, 'speeds.txt')\n",
    "speeds = {}\n",
    "with open(speedfile) as fp:\n",
    "    for line in fp:\n",
    "        imfile, _, _, left_speed, right_speed = line.strip().split(',')\n",
    "        speeds[imfile] = [left_speed, right_speed]\n",
    "    \n",
    "nbtest = int(len(imfiles)*0.1)\n",
    "test_filenames, train_filenames = imfiles[:nbtest], imfiles[nbtest:]\n",
    "test_x = np.array([\n",
    "    imresize(imread(os.path.join(imdir, f)), (120, 160))\n",
    "    for f in test_filenames\n",
    "])\n",
    "train_x = np.array([\n",
    "    imresize(imread(os.path.join(imdir, f)), (120, 160))\n",
    "    for f in train_filenames\n",
    "])\n",
    "test_y, train_y = [np.array([speeds[f] for f in fileset], dtype=np.float) / 255.0\n",
    "                    for fileset in (test_filenames, train_filenames)]\n",
    "\n",
    "print('Shapes: train_x: {}, train_y: {}, test_x: {}, test_y: {}'.format(\n",
    "    train_x.shape, train_y.shape, test_x.shape, test_y.shape\n",
    "));\n",
    "\n",
    "print(train_y.min(), train_y.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the model can be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:24: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6358 samples, validate on 707 samples\n",
      "Epoch 1/100\n",
      "6358/6358 [==============================] - 3s 492us/step - loss: 0.0064 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00588, saving model to aveta-checkpoint-20180510200434\n",
      "Epoch 2/100\n",
      "6358/6358 [==============================] - 3s 419us/step - loss: 0.0063 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00588\n",
      "Epoch 3/100\n",
      "6358/6358 [==============================] - 3s 416us/step - loss: 0.0062 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00588\n",
      "Epoch 4/100\n",
      "6358/6358 [==============================] - 3s 416us/step - loss: 0.0062 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00588 to 0.00587, saving model to aveta-checkpoint-20180510200434\n",
      "Epoch 5/100\n",
      "6358/6358 [==============================] - 3s 414us/step - loss: 0.0062 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00587\n",
      "Epoch 6/100\n",
      "6358/6358 [==============================] - 3s 412us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00587 to 0.00586, saving model to aveta-checkpoint-20180510200434\n",
      "Epoch 7/100\n",
      "6358/6358 [==============================] - 3s 408us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00586 to 0.00586, saving model to aveta-checkpoint-20180510200434\n",
      "Epoch 8/100\n",
      "6358/6358 [==============================] - 3s 406us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00586 to 0.00586, saving model to aveta-checkpoint-20180510200434\n",
      "Epoch 9/100\n",
      "6358/6358 [==============================] - 3s 406us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00586\n",
      "Epoch 10/100\n",
      "6358/6358 [==============================] - 3s 406us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00586 to 0.00586, saving model to aveta-checkpoint-20180510200434\n",
      "Epoch 11/100\n",
      "6358/6358 [==============================] - 3s 408us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00586\n",
      "Epoch 12/100\n",
      "6358/6358 [==============================] - 3s 405us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00586 to 0.00585, saving model to aveta-checkpoint-20180510200434\n",
      "Epoch 13/100\n",
      "6358/6358 [==============================] - 3s 406us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00585\n",
      "Epoch 14/100\n",
      "6358/6358 [==============================] - 3s 406us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00585 to 0.00584, saving model to aveta-checkpoint-20180510200434\n",
      "Epoch 15/100\n",
      "6358/6358 [==============================] - 3s 403us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00584\n",
      "Epoch 16/100\n",
      "6358/6358 [==============================] - 3s 403us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00584\n",
      "Epoch 17/100\n",
      "6358/6358 [==============================] - 3s 403us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00584\n",
      "Epoch 18/100\n",
      "6358/6358 [==============================] - 3s 402us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00584\n",
      "Epoch 19/100\n",
      "6358/6358 [==============================] - 3s 402us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00584\n",
      "785/785 [==============================] - 0s 332us/step\n",
      "0.0061970079009225415\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "checkpoint_filename = 'aveta-checkpoint-{}'.format(now.strftime('%Y%m%d%H%M%S'))\n",
    "save_best = ModelCheckpoint(checkpoint_filename,\n",
    "                            save_best_only=True,\n",
    "                            verbose=1,\n",
    "                            mode='min')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           min_delta=0,\n",
    "                           patience=5,\n",
    "                           verbose=0,\n",
    "                           mode='auto')\n",
    "\n",
    "cbs = [save_best, early_stop]\n",
    "\n",
    "batch_size = 320 if not TEST_MODE else 64\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(train_x,\n",
    "          train_y,\n",
    "          nb_epoch=100,\n",
    "          validation_split=0.1,\n",
    "          callbacks=cbs,\n",
    "          batch_size=batch_size)\n",
    "\n",
    "test_eval = model.evaluate(test_x, test_y, batch_size=batch_size)\n",
    "print(test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
